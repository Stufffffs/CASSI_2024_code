{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gzip\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataWDBH_path = 'processed_data/WDBH_data.csv'\n",
    "# data_path = 'data/simulation_data'\n",
    "dataWDBH_path = 'processed_data/updated_WDBH_data.csv'\n",
    "data_path = 'data/updated_simulation_data'\n",
    "\n",
    "id_WD = [10, 11, 12]\n",
    "id_BH = [14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check repeats\n",
    "def filter_consecutive_duplicates_with_map(input_list):\n",
    "    n = len(input_list)\n",
    "    keep = [True] * n  # Initialize all elements to True in the keep map\n",
    "    \n",
    "    i = 1\n",
    "    while i < n:\n",
    "        if input_list[i] == input_list[i - 1]:\n",
    "            # Mark all consecutive identical numbers to False except the last one\n",
    "            start = i - 1\n",
    "            while i < n and input_list[i] == input_list[i - 1]:\n",
    "                keep[i] = False\n",
    "                i += 1\n",
    "            keep[start] = True  # Keep the first of the consecutive identical numbers\n",
    "            keep[i - 1] = True  # Keep the last of the consecutive identical numbers\n",
    "        i += 1\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5761\n",
      "909\n",
      "32\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### Filter by age, RLO, and consecutive duplicates\n",
    "header = \"#N,#rv,#rg,#z,#t_snapshot[myr],#M1[MSUN],#M2[MSUN],#k1,#k2,#id1,#id2,#sma[AU],#ecc,#bin_star_radius0[RSUN],#bin_star_radius1[RSUN],#snapshot, #roche_lobe1_calc[RSUN], #roche_lobe2_calc[RSUN],#radrol0,#radrol1\"\n",
    "events_WDBH = []\n",
    "\n",
    "# Parse the csv file\n",
    "with open(dataWDBH_path, mode='r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        events_WDBH.append(row)\n",
    "    events_WDBH = np.array(events_WDBH)\n",
    "\n",
    "print(len(events_WDBH))\n",
    "\n",
    "# Check age\n",
    "check_old = np.array(events_WDBH[:, 4], dtype=float) > 9e3\n",
    "events_old = events_WDBH[check_old]\n",
    "print(len(events_old))\n",
    "\n",
    "# Check RLO\n",
    "check_RLO = ((np.array(events_old[:, 16]).astype(float) < np.array(events_old[:, 13]).astype(float)) | (np.array(events_old[:, 17]).astype(float) < np.array(events_old[:, 14]).astype(float)));\n",
    "events_RLO = events_old[check_RLO]\n",
    "print(len(events_RLO))\n",
    "\n",
    "# Check consecutives\n",
    "keep = filter_consecutive_duplicates_with_map(events_RLO[:, 9])\n",
    "events_consec = np.array([events_RLO[idx] for idx, flag in enumerate(keep) if flag])\n",
    "print(len(events_consec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputfiltered_file = 'processed_data/updated_WDBH_filtered.csv'\n",
    "\n",
    "### Write the data to the output file\n",
    "with open(outputfiltered_file, 'w') as file:\n",
    "    # Write the header\n",
    "    file.write(header + '\\n')\n",
    "\n",
    "    # Write the data\n",
    "    for row in events_consec:\n",
    "        file.write(','.join(map(str, row)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DONE print out the radius of the stars too. calculate size of roche lobe (formula), check if wd fills roche lobe. cut the ones that aren't. \n",
    "\n",
    "DONE cut interactions ealier than 9gyr. check for repeats, only keep first and last interaction. \n",
    "\n",
    "\n",
    "DONE check escaped binaries. i.e. record last binary interaction time, record escape time. \n",
    "if not escaped, check binint to see how the binary broke apart. \n",
    "\n",
    "to check binary formation, check binint to see when first time binary appears in output (making sure same binary is not in the input). binint produce list of systems, and then check through with data file again if there's any missing in either one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE use radrol number to create list again.\n",
    "\n",
    "use binint to find the binary, check ids are the same, calculate roche lobe radius. find latest time the binary appears in binint file with $(t_{enc}<t_{snap})\\,\\&\\,(R_{WD}<R_{RL})$. this tells us about the properties of the binary at formation. probably won't have more interactions that break it apart in between RLO and snapshot. can do by cross checking roche lobe with binint files. \n",
    "\n",
    "use binint to get story for the formation of each system\n",
    "\n",
    "check BH giant collisions from new file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5761\n",
      "909\n",
      "32\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### Filter by age, RLO, and consecutive duplicates\n",
    "header = \"#N,#rv,#rg,#z,#t_snapshot[myr],#M1[MSUN],#M2[MSUN],#k1,#k2,#id1,#id2,#sma[AU],#ecc,#bin_star_radius0[RSUN],#bin_star_radius1[RSUN],#snapshot, #roche_lobe1_calc[RSUN], #roche_lobe2_calc[RSUN],#radrol0,#radrol1\"\n",
    "\n",
    "events_WDBH = []\n",
    "\n",
    "\n",
    "\n",
    "# Parse the csv file\n",
    "with open(dataWDBH_path, mode='r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        events_WDBH.append(row)\n",
    "    events_WDBH = np.array(events_WDBH)\n",
    "\n",
    "print(len(events_WDBH))\n",
    "\n",
    "# Check age\n",
    "check_old = np.array(events_WDBH[:, 4], dtype=float) > 9e3\n",
    "events_old = events_WDBH[check_old]\n",
    "print(len(events_old))\n",
    "\n",
    "# Check RLO\n",
    "check_RLO = ((np.array(events_old[:, 18]).astype(float) > 1) | (np.array(events_old[:, 19]).astype(float) > 1));\n",
    "events_RLO = events_old[check_RLO]\n",
    "print(len(events_RLO))\n",
    "\n",
    "# Check consecutives\n",
    "keep = filter_consecutive_duplicates_with_map(events_RLO[:, 9])\n",
    "events_consec = np.array([events_RLO[idx] for idx, flag in enumerate(keep) if flag])\n",
    "print(len(events_consec))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputfiltered_file = 'processed_data/updated_WDBH_filtered_radrol.csv'\n",
    "\n",
    "### Write the data to the output file\n",
    "with open(outputfiltered_file, 'w') as file:\n",
    "    # Write the header\n",
    "    file.write(header + '\\n')\n",
    "\n",
    "    # Write the data\n",
    "    for row in events_consec:\n",
    "        file.write(','.join(map(str, row)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
